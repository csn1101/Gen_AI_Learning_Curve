{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sengu\\anaconda3\\envs\\genai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\sengu\\anaconda3\\envs\\genai\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "c:\\Users\\sengu\\anaconda3\\envs\\genai\\lib\\site-packages\\transformers\\tokenization_utils_base.py:4072: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
      "\n",
      "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
      "this:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "labels = tokenizer(text_target=tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Page' object has no attribute 'is_pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 108\u001b[0m\n\u001b[0;32m    105\u001b[0m     translated_pages\u001b[38;5;241m.\u001b[39mappend(translated_page)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Create the translated PDF\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m \u001b[43mcreate_translated_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_pages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslated_pages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_pdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslated PDF saved at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_pdf_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 81\u001b[0m, in \u001b[0;36mcreate_translated_pdf\u001b[1;34m(pages, translated_pages, output_pdf_path)\u001b[0m\n\u001b[0;32m     79\u001b[0m     page \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mnew_page(width\u001b[38;5;241m=\u001b[39mletter[\u001b[38;5;241m0\u001b[39m], height\u001b[38;5;241m=\u001b[39mletter[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     80\u001b[0m     overlay \u001b[38;5;241m=\u001b[39m new_pdf\u001b[38;5;241m.\u001b[39mload_page(i)\n\u001b[1;32m---> 81\u001b[0m     \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_pdf_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m output\u001b[38;5;241m.\u001b[39msave(output_pdf_path)\n",
      "File \u001b[1;32mc:\\Users\\sengu\\anaconda3\\envs\\genai\\lib\\site-packages\\pymupdf\\utils.py:160\u001b[0m, in \u001b[0;36mshow_pdf_page\u001b[1;34m(page, rect, src, pno, keep_proportion, overlay, oc, rotate, clip)\u001b[0m\n\u001b[0;32m    157\u001b[0m pymupdf\u001b[38;5;241m.\u001b[39mCheckParent(page)\n\u001b[0;32m    158\u001b[0m doc \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mis_pdf \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_pdf\u001b[49m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis no PDF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rect\u001b[38;5;241m.\u001b[39mis_empty \u001b[38;5;129;01mor\u001b[39;00m rect\u001b[38;5;241m.\u001b[39mis_infinite:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Page' object has no attribute 'is_pdf'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError occurred: 'Page' object has no attribute 'is_pdf'\n",
      "Skipping translation and PDF creation.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "import io\n",
    "\n",
    "# Extract text and formatting from the PDF\n",
    "def extract_text_and_formatting(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    pages = []\n",
    "    for page_num in range(len(document)):\n",
    "        try:\n",
    "            page = document.load_page(page_num)\n",
    "        except AttributeError:\n",
    "            continue  # Skip pages that raise AttributeError\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        page_content = []\n",
    "        for block in blocks:\n",
    "            if block[\"type\"] == 0:  # text block\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        page_content.append({\n",
    "                            \"text\": span[\"text\"],\n",
    "                            \"size\": span[\"size\"],\n",
    "                            \"flags\": span[\"flags\"],\n",
    "                            \"font\": span[\"font\"],\n",
    "                            \"color\": span[\"color\"],\n",
    "                            \"bbox\": span[\"bbox\"]\n",
    "                        })\n",
    "        pages.append(page_content)\n",
    "    return pages\n",
    "\n",
    "# Translate text using MarianMT\n",
    "def translate_text(text, target_language):\n",
    "    model_name = f\"Helsinki-NLP/opus-mt-en-{target_language}\"\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    \n",
    "    translated_text = []\n",
    "    for t in text:\n",
    "        if t.strip():  # Avoid empty strings\n",
    "            batch = tokenizer(t, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
    "            gen = model.generate(**batch)\n",
    "            translated = tokenizer.batch_decode(gen, skip_special_tokens=True)[0]\n",
    "            translated_text.append(translated)\n",
    "        else:\n",
    "            translated_text.append(t)\n",
    "    return translated_text\n",
    "\n",
    "# Create a translated PDF with the same formatting\n",
    "def create_translated_pdf(pages, translated_pages, output_pdf_path):\n",
    "    packet = io.BytesIO()\n",
    "    can = canvas.Canvas(packet, pagesize=letter)\n",
    "    width, height = letter\n",
    "\n",
    "    for page_num, page_content in enumerate(translated_pages):\n",
    "        for span in page_content:\n",
    "            x0, y0, x1, y1 = span[\"bbox\"]\n",
    "            y = height - y0  # Convert to PDF coordinate system\n",
    "            # Map the font to a standard font\n",
    "            font_name = span[\"font\"]\n",
    "            if 'Bold' in font_name:\n",
    "                can.setFont(\"Helvetica-Bold\", span[\"size\"])\n",
    "            elif 'Italic' in font_name or 'Oblique' in font_name:\n",
    "                can.setFont(\"Helvetica-Oblique\", span[\"size\"])\n",
    "            else:\n",
    "                can.setFont(\"Helvetica\", span[\"size\"])\n",
    "            \n",
    "            r, g, b = span[\"color\"] if isinstance(span[\"color\"], tuple) else (0, 0, 0)\n",
    "            can.setFillColorRGB(r / 255, g / 255, b / 255)\n",
    "            can.drawString(x0, y, span[\"text\"])\n",
    "        can.showPage()\n",
    "\n",
    "    can.save()\n",
    "\n",
    "    # Move to the beginning of the StringIO buffer\n",
    "    packet.seek(0)\n",
    "    new_pdf = fitz.open(\"pdf\", packet)\n",
    "    output = fitz.open()\n",
    "\n",
    "    for i in range(len(new_pdf)):\n",
    "        page = output.new_page(width=letter[0], height=letter[1])\n",
    "        overlay = new_pdf.load_page(i)\n",
    "        page.show_pdf_page(page.rect, overlay)\n",
    "\n",
    "    output.save(output_pdf_path)\n",
    "\n",
    "# Paths\n",
    "pdf_path = r\"D:\\DS WorkFlow\\Github\\Gen_AI\\Langchain\\data\\smallpdf.pdf\"\n",
    "output_pdf_path = r\"D:\\DS WorkFlow\\Github\\Gen_AI\\Langchain\\data\\translated_pdf.pdf\"\n",
    "target_language = \"fr\"  # e.g., French\n",
    "\n",
    "try:\n",
    "    # Execute the process\n",
    "    extracted_pages = extract_text_and_formatting(pdf_path)\n",
    "    all_text = [span[\"text\"] for page in extracted_pages for span in page]\n",
    "    translated_text = translate_text(all_text, target_language)\n",
    "\n",
    "    # Reconstruct the translated pages\n",
    "    translated_pages = []\n",
    "    text_index = 0\n",
    "    for page in extracted_pages:\n",
    "        translated_page = []\n",
    "        for span in page:\n",
    "            translated_span = span.copy()\n",
    "            translated_span[\"text\"] = translated_text[text_index]\n",
    "            translated_page.append(translated_span)\n",
    "            text_index += 1\n",
    "        translated_pages.append(translated_page)\n",
    "\n",
    "    # Create the translated PDF\n",
    "    create_translated_pdf(extracted_pages, translated_pages, output_pdf_path)\n",
    "\n",
    "    print(f\"Translated PDF saved at: {output_pdf_path}\")\n",
    "\n",
    "except AttributeError as e:\n",
    "    print(f\"AttributeError occurred: {e}\")\n",
    "    print(\"Skipping translation and PDF creation.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Failed to translate and create PDF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to translate and create PDF.\n",
      "An error occurred: 'Page' object has no attribute 'is_pdf'\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "import io\n",
    "\n",
    "# Extract text and formatting from the PDF\n",
    "def extract_text_and_formatting(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    pages = []\n",
    "    for page_num in range(len(document)):\n",
    "        try:\n",
    "            page = document.load_page(page_num)\n",
    "            blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "            page_content = []\n",
    "            for block in blocks:\n",
    "                if block[\"type\"] == 0:  # text block\n",
    "                    for line in block[\"lines\"]:\n",
    "                        for span in line[\"spans\"]:\n",
    "                            page_content.append({\n",
    "                                \"text\": span[\"text\"],\n",
    "                                \"size\": span[\"size\"],\n",
    "                                \"flags\": span[\"flags\"],\n",
    "                                \"font\": span[\"font\"],\n",
    "                                \"color\": span[\"color\"],\n",
    "                                \"bbox\": span[\"bbox\"]\n",
    "                            })\n",
    "            pages.append(page_content)\n",
    "        except AttributeError:\n",
    "            print(\"AttributeError occurred: 'Page' object has no attribute 'is_pdf'\")\n",
    "            print(\"Skipping translation and PDF creation for this page.\")\n",
    "            continue\n",
    "    return pages\n",
    "\n",
    "# Translate text using MarianMT\n",
    "def translate_text(text, target_language):\n",
    "    model_name = f\"Helsinki-NLP/opus-mt-en-{target_language}\"\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    \n",
    "    translated_text = []\n",
    "    for t in text:\n",
    "        if t.strip():  # Avoid empty strings\n",
    "            batch = tokenizer(t, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
    "            gen = model.generate(**batch)\n",
    "            translated = tokenizer.batch_decode(gen, skip_special_tokens=True)[0]\n",
    "            translated_text.append(translated)\n",
    "        else:\n",
    "            translated_text.append(t)\n",
    "    return translated_text\n",
    "\n",
    "# Create a translated PDF with the same formatting\n",
    "def create_translated_pdf(pages, translated_pages, output_pdf_path):\n",
    "    packet = io.BytesIO()\n",
    "    can = canvas.Canvas(packet, pagesize=letter)\n",
    "    width, height = letter\n",
    "\n",
    "    for page_num, page_content in enumerate(translated_pages):\n",
    "        for span in page_content:\n",
    "            x0, y0, x1, y1 = span[\"bbox\"]\n",
    "            y = height - y0  # Convert to PDF coordinate system\n",
    "            # Map the font to a standard font\n",
    "            font_name = span[\"font\"]\n",
    "            if 'Bold' in font_name:\n",
    "                can.setFont(\"Helvetica-Bold\", span[\"size\"])\n",
    "            elif 'Italic' in font_name or 'Oblique' in font_name:\n",
    "                can.setFont(\"Helvetica-Oblique\", span[\"size\"])\n",
    "            else:\n",
    "                can.setFont(\"Helvetica\", span[\"size\"])\n",
    "            \n",
    "            r, g, b = span[\"color\"] if isinstance(span[\"color\"], tuple) else (0, 0, 0)\n",
    "            can.setFillColorRGB(r / 255, g / 255, b / 255)\n",
    "            can.drawString(x0, y, span[\"text\"])\n",
    "        can.showPage()\n",
    "\n",
    "    can.save()\n",
    "\n",
    "    # Move to the beginning of the StringIO buffer\n",
    "    packet.seek(0)\n",
    "    new_pdf = fitz.open(\"pdf\", packet)\n",
    "    output = fitz.open()\n",
    "\n",
    "    for i in range(len(new_pdf)):\n",
    "        page = output.new_page(width=letter[0], height=letter[1])\n",
    "        overlay = new_pdf.load_page(i)\n",
    "        page.show_pdf_page(page.rect, overlay)\n",
    "\n",
    "    output.save(output_pdf_path)\n",
    "\n",
    "# Paths\n",
    "pdf_path = r\"D:\\DS WorkFlow\\Github\\Gen_AI\\Langchain\\data\\smallpdf.pdf\"\n",
    "output_pdf_path = r\"D:\\DS WorkFlow\\Github\\Gen_AI\\Langchain\\data\\translated_pdf.pdf\"\n",
    "target_language = \"fr\"  # e.g., French\n",
    "\n",
    "try:\n",
    "    # Execute the process\n",
    "    extracted_pages = extract_text_and_formatting(pdf_path)\n",
    "    all_text = [span[\"text\"] for page in extracted_pages for span in page]\n",
    "    translated_text = translate_text(all_text, target_language)\n",
    "\n",
    "    # Reconstruct the translated pages\n",
    "    translated_pages = []\n",
    "    text_index = 0\n",
    "    for page in extracted_pages:\n",
    "        translated_page = []\n",
    "        for span in page:\n",
    "            translated_span = span.copy()\n",
    "            translated_span[\"text\"] = translated_text[text_index]\n",
    "            translated_page.append(translated_span)\n",
    "            text_index += 1\n",
    "        translated_pages.append(translated_page)\n",
    "\n",
    "    # Create the translated PDF\n",
    "    create_translated_pdf(extracted_pages, translated_pages, output_pdf_path)\n",
    "\n",
    "    print(f\"Translated PDF saved at: {output_pdf_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Failed to translate and create PDF.\")\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
